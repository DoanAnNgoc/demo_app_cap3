

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import os
from datetime import datetime, timedelta
from google.cloud import bigquery
from google.oauth2 import service_account
import json
from prophet import Prophet
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, mean_absolute_error, mean_squared_error, r2_score
import numpy as np
from scipy.interpolate import make_interp_spline
# Thiáº¿t láº­p xÃ¡c thá»±c Google BigQuery
#os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "D:/CÃ NHÃ‚N/terminal/terminal/etl-cap3-27b899b6d343.json"
#client = bigquery.Client(project='etl-cap3')
#st.image("D:/CÃ NHÃ‚N\ÄOÃ€N áº¤N NGá»ŒC.jpg", caption="", width=400)
# Thiáº¿t láº­p tiÃªu Ä‘á» vÃ  mÃ´ táº£
# Thiáº¿t láº­p xÃ¡c thá»±c Google BigQuery
# Thiáº¿t láº­p xÃ¡c thá»±c Google BigQuery vá»›i key nhÃºng trá»±c tiáº¿p
try:
    # Service account key nhÃºng trá»±c tiáº¿p
    service_account_key = {
        "type": "service_account",
        "project_id": "etl-cap3",
        "private_key_id": "27b899b6d343424542770bf84b577d2816e73701",
        "private_key": "-----BEGIN PRIVATE KEY-----\nMIIEvAIBADANBgkqhkiG9w0BAQEFAASCBKYwggSiAgEAAoIBAQCquHfMsTta8ClC\n2ChK/+70ZeIqzScSGQKLD6KcOPaA4A/dWVGqjHLE2MOaQyAyKqQvGAJxuWNbMVLN\nlb9Bt8pbPfsyUov3l80WwMUyv/3MupGghrKhTUai5S8WzsLvE3i+ti65YrS9KqwT\n8r6p+A45KiKHgiUBtMkZkhi/AtX+lYn3FlbHmR5hNioxM2ojumFqEzgy8JrvdDAg\nGaGvhDAf+k2KWAVHpdTB7cJl4YS4PUokl5F5ysl9/TCd9hEuISUYNL7c3YHJE5Go\nBQEZ9a+tjpLeS7hl968LcvP18Ln89SOHG2300wjWyUvmQUrvP/cfFU4dKoxhRAGY\nKQxkXmL5AgMBAAECggEAFj/vHSEGzgCkNVoGplUEx5rKXIRa+zjXOVh9pkP7nIBB\n5mSlssdAjfcnnGCd6ZaKdLjPA2it/PdIsL07gqJ5dRAhlPASiIpNkxGR9zNJLfgt\nfUZmMYTowoIsHkTZkwnD9YG47+BgEzy51eplKbHH6MYHtLF5hpIRQ4vkPcDDiGeu\nDgqyYYdlFXq4o8jCY5vLh/4E1GInRreQkOaGC8WdztrXSHLvsLHFAtF2mBvi4xbu\nakwRMivf8h+HCs5iKIejj87yPotFVmYYJY/BEWrELx/HpkHUY8GdL8ZbFax5EK/M\nL27JsPr7Q5rnXWFOpGqv10DiFUGg+b1ASWjrgkufoQKBgQDqLvWiUwXn/f4zl3Yy\nAQUGkAiASbvbXqSmlKES3gm3nA7ooRE1miAaWj1gSwgKSJglDJPU4qcZqkIW3cMh\nEw1PxR5CBHtfrYAzEu7r2WC7VoHOXCOn813juFyejAsEIgdk7KirlQAHlIdYH+Ts\n95A2ytv271QH3xGA7CNxzlb//wKBgQC6n/ubZGCAaXVm8KfapvV7Bycv4uwlhiKu\nS+C7WQBguTXHwoa/Q6hni4qJTQxM/Uw5HkEYKEqMAC9bTJ/jB9dyeUv51+X5ItNu\n24DS9ZO/X3upErJV0KcIleDbpZ1WB72kuwxr5v9Q6BO/GIDunsUfnxeSdZRQDoTY\nOuRJmwKdBwKBgFIAB3rDX3oQcgZWrshrmvrlTFS/fMwfo7/Ao3Yb0YM9XesPGxuN\n0Ffp6Tviifov2TZ/5PPSOXi/KU0gcccPCMY525J6R0kFU7KOmqJzB3ARpno/wSx6\nBxJJ6ASMPP9Bex1X0Ofj0JLW611sLZjcRt8owUUCIIZxEYv3I6IiAky5AoGAVhhc\nINHr2xHLwZOgPDTt5rXkFClhu+XntfT3Vja2/+gxsVhChZYW6L3tSW4sEJCCS49z\nhEuCKJglQL9Wu4vwjrT6oeZCB+9TDz9gbPIyGQVZrSQc9Y3uoP1T4MDElt23VXmd\nP2IvwwltoqkRQgQo+G+SllR7+XrZOk/g5TwHtp0CgYBCXjSsE4ldBd6fVlYGABGp\nGDI82Og1A5mOsK+zCwpHylBnXUO8kZzFhzZeVrj2at0INHDGVeUw1t0eLjLbSL2V\nRtzF3xSxeb1m+lvGYNmpmniujOXcaN6wI8JayHg0GHrTPrRK4Qn2ZZYGPvti2zdg\nQY+70nrAZtHSciN+oCRi9w==\n-----END PRIVATE KEY-----\n",
        "client_email": "etl-cap3@etl-cap3.iam.gserviceaccount.com",
        "client_id": "118374989078209513090",
        "auth_uri": "https://accounts.google.com/o/oauth2/auth",
        "token_uri": "https://oauth2.googleapis.com/token",
        "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
        "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/etl-cap3%40etl-cap3.iam.gserviceaccount.com",
        "universe_domain": "googleapis.com"
    }
    credentials = service_account.Credentials.from_service_account_info(service_account_key)
    client = bigquery.Client(project='etl-cap3', credentials=credentials)
except Exception as e:
    st.error(f"BigQuery authentication failed: {e}")
    st.stop()
#
st.title("Äá» Ãn Tá»‘t Nghiá»‡p - PhÃ¢n TÃ­ch Doanh Thu vÃ  PhÃ¢n Cá»¥m KhÃ¡ch HÃ ng")
st.markdown("""
á»¨ng dá»¥ng nÃ y hiá»ƒn thá»‹ phÃ¢n cá»¥m khÃ¡ch hÃ ng, dá»± Ä‘oÃ¡n doanh thu, 
vÃ  cÃ¡c biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch dá»±a trÃªn dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u á»Ÿ Google BigQuery sau quÃ¡ trÃ¬nh ETL Pipeline trÆ°á»›c Ä‘Ã³.
Báº¡n vui lÃ²ng chá»n tab Ä‘á»ƒ xem cÃ¡c phÃ¢n tÃ­ch chi tiáº¿t.
""")

# Táº£i dá»¯ liá»‡u tá»« BigQuery
@st.cache_data
def load_data():
    query = """
        SELECT * FROM etl-cap3.Sale_AMZ_ETSY.FinalData
        LIMIT 500000000
    """
    df = client.query(query).to_dataframe()
    df['Order Date'] = pd.to_datetime(df['Order Date'])
    df['year'] = df['Order Date'].dt.year
    return df

# Táº£i dá»¯ liá»‡u
with st.spinner("Äang táº£i dá»¯ liá»‡u tá»« BigQuery..."):
    df = load_data()

# Táº¡o cÃ¡c tab
tab1, tab2, tab3 = st.tabs(["ğŸ“Š Tá»•ng Quan Doanh Thu", "ğŸ’µ Dá»± ÄoÃ¡n Doanh Thu", "ğŸ“€ PhÃ¢n Cá»¥m KhÃ¡ch HÃ ng"])

# Tab 1: Tá»•ng Quan Doanh Thu
with tab1:
    st.header("ğŸ“Š Tá»•ng Quan Doanh Thu Theo NÄƒm")
    revenue_by_year = df.groupby('year')['Order Total'].sum().reset_index()

    # Váº½ biá»ƒu Ä‘á»“ doanh thu theo nÄƒm vá»›i Plotly
    fig = px.bar(revenue_by_year, x='year', y='Order Total', title='Tá»•ng Doanh Thu Theo NÄƒm',
                 labels={'year': 'NÄƒm', 'Order Total': 'Tá»•ng Doanh Thu'}, color_discrete_sequence=['red'])
    fig.update_layout(xaxis_tickangle=0, yaxis=dict(griddash='dash', gridcolor='gray'))
    st.plotly_chart(fig)

   # ThÃªm biá»ƒu Ä‘á»“ Tá»•ng Order Total theo Sub-Category (Ä‘á»™ng)
    st.subheader("Tá»•ng Order Total theo Sub-Category Theo NÄƒm")
    
    # TÃ­nh tá»•ng Order Total theo Sub-Category vÃ  Year
    df['Year'] = df['Order Date'].dt.year
    pivot_data = df.groupby(['Year', 'Sub Category'])['Order Total'].sum().unstack()

    # Láº¥y danh sÃ¡ch nÄƒm
    years = sorted(pivot_data.index)

    # Äá»‹nh nghÄ©a mÃ u theo nÄƒm (3 nÄƒm gáº§n nháº¥t)
    year_colors = {
        years[-3] if len(years) >= 3 else years[0]: '#1f77b4',  # blue
        years[-2] if len(years) >= 2 else years[0]: '#2ca02c',  # green
        years[-1] if len(years) >= 1 else years[0]: '#ff7f0e',  # orange
    }

    # Dropdown Ä‘á»ƒ chá»n nÄƒm
    selected_year = st.selectbox("Chá»n nÄƒm:", years, index=len(years)-1)

    # Váº½ biá»ƒu Ä‘á»“ cho nÄƒm Ä‘Æ°á»£c chá»n
    if years:
        data = pivot_data.loc[selected_year].sort_values()
        top5 = data.nlargest(5).index

        # Äáº·t mÃ u: top 5 mÃ u khÃ¡c (Ä‘áº­m), cÃ²n láº¡i lÃ  mÃ u nháº¡t
        colors = [year_colors.get(selected_year, 'lightgray') if subcat in top5 else 'lightgray' for subcat in data.index]

        # Táº¡o figure
        plt.figure(figsize=(10, 6))
        bars = plt.barh(data.index, data.values, color=colors)
        
        # Ghi nhÃ£n giÃ¡ trá»‹ trÃªn cá»™t
        for bar in bars:
            width = bar.get_width()
            plt.text(width + 0.5, bar.get_y() + bar.get_height()/2,
                     f'{width:,.2f}', va='center', fontsize=9)

        plt.title(f'Tá»•ng Doanh thu theo Sub-Category - NÄƒm {selected_year}')
        plt.xlabel('Tá»•ng Order Total')
        plt.ylabel('Sub-Category')
        plt.grid(True, axis='x', linestyle='--', alpha=0.7)
        plt.tight_layout()
        
        # Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ trong Streamlit
        st.pyplot(plt.gcf())
        plt.close()  # ÄÃ³ng figure Ä‘á»ƒ trÃ¡nh xung Ä‘á»™t
    else:
        st.warning("KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ theo Sub-Category.")
# Tab 2: Dá»± ÄoÃ¡n Doanh Thu
with tab2:
    st.header("ğŸ’µ Dá»± ÄoÃ¡n Doanh Thu vá»›i Prophet")

    # Chuáº©n bá»‹ dá»¯ liá»‡u cho Prophet
    prophet_df = df[['Order Date', 'Order Total']].rename(columns={'Order Date': 'ds', 'Order Total': 'y'})
    prophet_df = prophet_df.groupby('ds').sum().reset_index()

    # LÃ m mÆ°á»£t dá»¯ liá»‡u thá»±c táº¿
    prophet_df['y_smooth'] = prophet_df['y'].rolling(window=5, center=True, min_periods=1).mean()
    prophet_df['ds_numeric'] = prophet_df['ds'].apply(lambda x: x.timestamp())
    prophet_df = prophet_df.sort_values('ds_numeric')

    # Ná»™i suy Ä‘á»ƒ lÃ m mÆ°á»£t
    x = prophet_df['ds_numeric']
    y = prophet_df['y_smooth']
    x_smooth = np.linspace(x.min(), x.max(), 500)
    spl = make_interp_spline(x, y, k=3)
    y_smooth = spl(x_smooth)
    ds_smooth = pd.to_datetime(x_smooth, unit='s')

    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh Prophet
    model = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=True, changepoint_prior_scale=0.01)
    model.fit(prophet_df)

    # Biá»ƒu Ä‘á»“ 1: Thá»±c táº¿ vÃ  dá»± Ä‘oÃ¡n trong pháº¡m vi dá»¯ liá»‡u gá»‘c
    past_future = prophet_df[['ds']].copy()
    past_forecast = model.predict(past_future)
    past_forecast['yhat_smooth'] = past_forecast['yhat'].rolling(window=5, center=True, min_periods=1).mean()
    past_forecast['yhat_lower_smooth'] = past_forecast['yhat_lower'].rolling(window=5, center=True, min_periods=1).mean()
    past_forecast['yhat_upper_smooth'] = past_forecast['yhat_upper'].rolling(window=5, center=True, min_periods=1).mean()

    # Váº½ biá»ƒu Ä‘á»“ vá»›i Plotly
    fig1 = go.Figure()
    fig1.add_trace(go.Scatter(x=ds_smooth, y=y_smooth, mode='lines', name='Thá»±c táº¿', line=dict(color='blue', width=1)))
    fig1.add_trace(go.Scatter(x=past_forecast['ds'], y=past_forecast['yhat_smooth'], mode='lines', name='Dá»± Ä‘oÃ¡n', line=dict(color='orange', width=1)))
    fig1.add_trace(go.Scatter(x=past_forecast['ds'], y=past_forecast['yhat_upper_smooth'], mode='lines', name='Khoáº£ng tin cáº­y (trÃªn)', line=dict(color='yellow', width=0), showlegend=False))
    fig1.add_trace(go.Scatter(x=past_forecast['ds'], y=past_forecast['yhat_lower_smooth'], mode='lines', name='Khoáº£ng tin cáº­y (dÆ°á»›i)', line=dict(color='yellow', width=0), fill='tonexty', fillcolor='rgba(255, 255, 0, 0.2)'))
    fig1.update_layout(title='GiÃ¡ trá»‹ bÃ¡n hÃ ng hÃ ng thÃ¡ng - Prophet (Táº­p gá»‘c)', xaxis_title='NgÃ y', yaxis_title='GiÃ¡ trá»‹ bÃ¡n hÃ ng', xaxis_tickformat='%Y-%m', xaxis_tickangle=45, yaxis=dict(griddash='dash', gridcolor='gray'))
    st.plotly_chart(fig1)

    # Biá»ƒu Ä‘á»“ 2: Dá»± Ä‘oÃ¡n 12 thÃ¡ng tiáº¿p theo
    future = model.make_future_dataframe(periods=365, freq='D')
    future_forecast = model.predict(future)
    future_forecast['yhat_smooth'] = future_forecast['yhat'].rolling(window=5, center=True, min_periods=1).mean()
    future_forecast['yhat_lower_smooth'] = future_forecast['yhat_lower'].rolling(window=5, center=True, min_periods=1).mean()
    future_forecast['yhat_upper_smooth'] = future_forecast['yhat_upper'].rolling(window=5, center=True, min_periods=1).mean()

    # Váº½ biá»ƒu Ä‘á»“ dá»± Ä‘oÃ¡n tÆ°Æ¡ng lai
    fig2 = go.Figure()
    fig2.add_trace(go.Scatter(x=ds_smooth, y=y_smooth, mode='lines', name='Thá»±c táº¿', line=dict(color='blue', width=1)))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              y=future_forecast['yhat_smooth'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              mode='lines', name='Dá»± Ä‘oÃ¡n', line=dict(color='orange', width=1)))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] > prophet_df['ds'].max()],
                              y=future_forecast['yhat_smooth'][future_forecast['ds'] > prophet_df['ds'].max()],
                              mode='lines', name='Dá»± Ä‘oÃ¡n tÆ°Æ¡ng lai', line=dict(color='red', width=1)))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              y=future_forecast['yhat_upper_smooth'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              mode='lines', name='Khoáº£ng tin cáº­y', line=dict(color='yellow', width=0), showlegend=False))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              y=future_forecast['yhat_lower_smooth'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              mode='lines', name='Khoáº£ng tin cáº­y', line=dict(color='yellow', width=0), fill='tonexty', fillcolor='rgba(255, 255, 0, 0.2)'))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] > prophet_df['ds'].max()],
                              y=future_forecast['yhat_upper_smooth'][future_forecast['ds'] > prophet_df['ds'].max()],
                              mode='lines', name='Khoáº£ng tin cáº­y tÆ°Æ¡ng lai', line=dict(color='pink', width=0), showlegend=False))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] > prophet_df['ds'].max()],
                              y=future_forecast['yhat_lower_smooth'][future_forecast['ds'] > prophet_df['ds'].max()],
                              mode='lines', name='Khoáº£ng tin cáº­y tÆ°Æ¡ng lai', line=dict(color='pink', width=0), fill='tonexty', fillcolor='rgba(255, 192, 203, 0.2)'))
    fig2.update_layout(title='Dá»± Ä‘oÃ¡n giÃ¡ trá»‹ bÃ¡n hÃ ng 12 thÃ¡ng tiáº¿p theo - Prophet', xaxis_title='NgÃ y', yaxis_title='GiÃ¡ trá»‹ bÃ¡n hÃ ng', xaxis_tickformat='%Y-%m', xaxis_tickangle=45, yaxis=dict(griddash='dash', gridcolor='gray'))
    st.plotly_chart(fig2)

    # Hiá»ƒn thá»‹ cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡
    eval_df = pd.merge(prophet_df[['ds', 'y']], past_forecast[['ds', 'yhat']], on='ds')
    mae = mean_absolute_error(eval_df['y'], eval_df['yhat'])
    rmse = np.sqrt(mean_squared_error(eval_df['y'], eval_df['yhat']))
    mape = np.mean(np.abs((eval_df['y'] - eval_df['yhat']) / eval_df['y'])) * 100
    r2 = r2_score(eval_df['y'], eval_df['yhat'])

    st.subheader("ÄÃ¡nh GiÃ¡ MÃ´ HÃ¬nh Dá»± ÄoÃ¡n")
    st.write(f"ğŸ“Š MAE: {mae:.2f}")
    st.write(f"ğŸ“Š RMSE: {rmse:.2f}")
    st.write(f"ğŸ“Š MAPE: {mape:.2f}%")
    st.write(f"ğŸ“Š RÂ² Score: {r2:.2f}")

    # ThÃªm má»¥c chá»n ngÃ y Ä‘á»ƒ dá»± Ä‘oÃ¡n doanh thu
    st.subheader("Dá»± ÄoÃ¡n Doanh Thu Cho NgÃ y Cá»¥ Thá»ƒ")
    today = datetime.today().date()
    max_date = today + timedelta(days=365)  # Giá»›i háº¡n 1 nÄƒm tá»« hÃ´m nay
    selected_date = st.date_input("Chá»n ngÃ y trong tÆ°Æ¡ng lai Ä‘á»ƒ dá»± Ä‘oÃ¡n doanh thu:", 
                                  min_value=today, 
                                  max_value=max_date, 
                                  value=today + timedelta(days=30))

    # Dá»± Ä‘oÃ¡n cho ngÃ y Ä‘Æ°á»£c chá»n
    selected_date_df = pd.DataFrame({'ds': [pd.to_datetime(selected_date)]})
    selected_forecast = model.predict(selected_date_df)

    # Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n
    st.markdown(f"**Dá»± Ä‘oÃ¡n doanh thu cho ngÃ y {selected_date}:**")
    st.write(f"ğŸ“ˆ GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n: **${selected_forecast['yhat'].iloc[0]:,.2f}**")
    st.write(f"ğŸ“‰ Khoáº£ng tin cáº­y tháº¥p: **${selected_forecast['yhat_lower'].iloc[0]:,.2f}**")
    st.write(f"ğŸ“Š Khoáº£ng tin cáº­y cao: **${selected_forecast['yhat_upper'].iloc[0]:,.2f}**")
# Tab 3: PhÃ¢n Cá»¥m KhÃ¡ch HÃ ng
with tab3:
    st.header("ğŸ“€ PhÃ¢n Cá»¥m KhÃ¡ch HÃ ng vá»›i GMM")

    # Láº¥y máº«u dá»¯ liá»‡u
    df_sample = df.sample(n=35000, random_state=42)
    df_cluster = df_sample[['Product Cost', 'Shipping Fee', 'Order Total', 'Profit']]

    # Chuáº©n hÃ³a vÃ  PCA
    scaler = StandardScaler()
    df_scaled = scaler.fit_transform(df_cluster)
    pca = PCA(n_components=2)
    df_pca = pca.fit_transform(df_scaled)

    # PhÃ¢n cá»¥m vá»›i GMM
    gmm = GaussianMixture(n_components=7, random_state=42)
    clusters = gmm.fit_predict(df_pca)
    df_sample['Cluster'] = clusters

    # Váº½ biá»ƒu Ä‘á»“ phÃ¢n cá»¥m
    fig3 = px.scatter(x=df_pca[:, 0], y=df_pca[:, 1], color=clusters.astype(str), title='PhÃ¢n Cá»¥m KhÃ¡ch HÃ ng vá»›i GMM',
                      labels={'x': 'PCA 1', 'y': 'PCA 2', 'color': 'Cluster'}, color_discrete_sequence=px.colors.qualitative.T10)
    fig3.update_layout(showlegend=True)
    st.plotly_chart(fig3)

    # Hiá»ƒn thá»‹ káº¿t quáº£ phÃ¢n cá»¥m
    st.subheader("Káº¿t Quáº£ PhÃ¢n Cá»¥m (Máº«u)")
    st.dataframe(df_sample[['Order Id', 'City', 'Country', 'Cluster']].head())

    # PhÃ¢n tÃ­ch Ä‘áº·c trÆ°ng tá»«ng cá»¥m
    df_analysis = df_sample[['Product Cost', 'Shipping Fee', 'Order Total', 'Profit', 'Cluster']].copy()
    cluster_summary = df_analysis.groupby('Cluster').mean().round(2)
    cluster_counts = df_analysis['Cluster'].value_counts().sort_index()
    cluster_summary['Count'] = cluster_counts

    st.subheader("Äáº·c TrÆ°ng Trung BÃ¬nh cá»§a Tá»«ng Cá»¥m")
    st.dataframe(cluster_summary)

    # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh phÃ¢n cá»¥m (tá»« Tab 4)
    st.subheader("ÄÃ¡nh GiÃ¡ MÃ´ HÃ¬nh PhÃ¢n Cá»¥m")
    df_valid = df_sample.dropna(subset=['Cluster'])
    X_valid = df_pca
    labels = df_valid['Cluster']

    sil_score = silhouette_score(X_valid, labels)
    db_index = davies_bouldin_score(X_valid, labels)
    ch_index = calinski_harabasz_score(X_valid, labels)

    st.write(f"ğŸ“Š Silhouette Score: {sil_score:.3f}")
    st.write(f"ğŸ“Š Davies-Bouldin Index: {db_index:.3f}")
    st.write(f"ğŸ“Š Calinski-Harabasz Index: {ch_index:.3f}")
    st.write(f"ğŸ“Š Sá»‘ cá»¥m: {len(set(labels))}")

# Footer
st.markdown("---")
st.markdown("Web App Demo Äá» Ãn Tá»‘t Nghiá»‡p Ä‘Æ°á»£c xÃ¢y dá»±ng vá»›i Streamlit bá»Ÿi áº¤n Ngá»c . LiÃªn há»‡ há»— trá»£: anngocmukbang@gmail.com")
