

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import os
from datetime import datetime, timedelta
from google.cloud import bigquery
from google.oauth2 import service_account
import json
from prophet import Prophet
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, mean_absolute_error, mean_squared_error, r2_score
import numpy as np
from scipy.interpolate import make_interp_spline
# Thi·∫øt l·∫≠p x√°c th·ª±c Google BigQuery
#os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "D:/C√Å NH√ÇN/terminal/terminal/etl-cap3-27b899b6d343.json"
#client = bigquery.Client(project='etl-cap3')
#st.image("D:/C√Å NH√ÇN\ƒêO√ÄN ·∫§N NG·ªåC.jpg", caption="", width=400)
# Thi·∫øt l·∫≠p ti√™u ƒë·ªÅ v√† m√¥ t·∫£
# Thi·∫øt l·∫≠p x√°c th·ª±c Google BigQuery
# Thi·∫øt l·∫≠p x√°c th·ª±c Google BigQuery v·ªõi key nh√∫ng tr·ª±c ti·∫øp
try:
    # Service account key nh√∫ng tr·ª±c ti·∫øp
    service_account_key = {
        "type": "service_account",
        "project_id": "etl-cap3",
        "private_key_id": "27b899b6d343424542770bf84b577d2816e73701",
        "private_key": "-----BEGIN PRIVATE KEY-----\nMIIEvAIBADANBgkqhkiG9w0BAQEFAASCBKYwggSiAgEAAoIBAQCquHfMsTta8ClC\n2ChK/+70ZeIqzScSGQKLD6KcOPaA4A/dWVGqjHLE2MOaQyAyKqQvGAJxuWNbMVLN\nlb9Bt8pbPfsyUov3l80WwMUyv/3MupGghrKhTUai5S8WzsLvE3i+ti65YrS9KqwT\n8r6p+A45KiKHgiUBtMkZkhi/AtX+lYn3FlbHmR5hNioxM2ojumFqEzgy8JrvdDAg\nGaGvhDAf+k2KWAVHpdTB7cJl4YS4PUokl5F5ysl9/TCd9hEuISUYNL7c3YHJE5Go\nBQEZ9a+tjpLeS7hl968LcvP18Ln89SOHG2300wjWyUvmQUrvP/cfFU4dKoxhRAGY\nKQxkXmL5AgMBAAECggEAFj/vHSEGzgCkNVoGplUEx5rKXIRa+zjXOVh9pkP7nIBB\n5mSlssdAjfcnnGCd6ZaKdLjPA2it/PdIsL07gqJ5dRAhlPASiIpNkxGR9zNJLfgt\nfUZmMYTowoIsHkTZkwnD9YG47+BgEzy51eplKbHH6MYHtLF5hpIRQ4vkPcDDiGeu\nDgqyYYdlFXq4o8jCY5vLh/4E1GInRreQkOaGC8WdztrXSHLvsLHFAtF2mBvi4xbu\nakwRMivf8h+HCs5iKIejj87yPotFVmYYJY/BEWrELx/HpkHUY8GdL8ZbFax5EK/M\nL27JsPr7Q5rnXWFOpGqv10DiFUGg+b1ASWjrgkufoQKBgQDqLvWiUwXn/f4zl3Yy\nAQUGkAiASbvbXqSmlKES3gm3nA7ooRE1miAaWj1gSwgKSJglDJPU4qcZqkIW3cMh\nEw1PxR5CBHtfrYAzEu7r2WC7VoHOXCOn813juFyejAsEIgdk7KirlQAHlIdYH+Ts\n95A2ytv271QH3xGA7CNxzlb//wKBgQC6n/ubZGCAaXVm8KfapvV7Bycv4uwlhiKu\nS+C7WQBguTXHwoa/Q6hni4qJTQxM/Uw5HkEYKEqMAC9bTJ/jB9dyeUv51+X5ItNu\n24DS9ZO/X3upErJV0KcIleDbpZ1WB72kuwxr5v9Q6BO/GIDunsUfnxeSdZRQDoTY\nOuRJmwKdBwKBgFIAB3rDX3oQcgZWrshrmvrlTFS/fMwfo7/Ao3Yb0YM9XesPGxuN\n0Ffp6Tviifov2TZ/5PPSOXi/KU0gcccPCMY525J6R0kFU7KOmqJzB3ARpno/wSx6\nBxJJ6ASMPP9Bex1X0Ofj0JLW611sLZjcRt8owUUCIIZxEYv3I6IiAky5AoGAVhhc\nINHr2xHLwZOgPDTt5rXkFClhu+XntfT3Vja2/+gxsVhChZYW6L3tSW4sEJCCS49z\nhEuCKJglQL9Wu4vwjrT6oeZCB+9TDz9gbPIyGQVZrSQc9Y3uoP1T4MDElt23VXmd\nP2IvwwltoqkRQgQo+G+SllR7+XrZOk/g5TwHtp0CgYBCXjSsE4ldBd6fVlYGABGp\nGDI82Og1A5mOsK+zCwpHylBnXUO8kZzFhzZeVrj2at0INHDGVeUw1t0eLjLbSL2V\nRtzF3xSxeb1m+lvGYNmpmniujOXcaN6wI8JayHg0GHrTPrRK4Qn2ZZYGPvti2zdg\nQY+70nrAZtHSciN+oCRi9w==\n-----END PRIVATE KEY-----\n",
        "client_email": "etl-cap3@etl-cap3.iam.gserviceaccount.com",
        "client_id": "118374989078209513090",
        "auth_uri": "https://accounts.google.com/o/oauth2/auth",
        "token_uri": "https://oauth2.googleapis.com/token",
        "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
        "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/etl-cap3%40etl-cap3.iam.gserviceaccount.com",
        "universe_domain": "googleapis.com"
    }
    credentials = service_account.Credentials.from_service_account_info(service_account_key)
    client = bigquery.Client(project='etl-cap3', credentials=credentials)
except Exception as e:
    st.error(f"BigQuery authentication failed: {e}")
    st.stop()
#
st.title("ƒê·ªÅ √Ån T·ªët Nghi·ªáp - Ph√¢n T√≠ch Doanh Thu v√† Ph√¢n C·ª•m Kh√°ch H√†ng")
st.markdown("""
·ª®ng d·ª•ng n√†y hi·ªÉn th·ªã ph√¢n c·ª•m kh√°ch h√†ng, d·ª± ƒëo√°n doanh thu, 
v√† c√°c bi·ªÉu ƒë·ªì ph√¢n t√≠ch d·ª±a tr√™n d·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u ·ªü Google BigQuery sau qu√° tr√¨nh ETL Pipeline tr∆∞·ªõc ƒë√≥.
B·∫°n vui l√≤ng ch·ªçn tab ƒë·ªÉ xem c√°c ph√¢n t√≠ch chi ti·∫øt.
""")

# T·∫£i d·ªØ li·ªáu t·ª´ BigQuery
@st.cache_data
def load_data():
    query = """
        SELECT * FROM etl-cap3.Sale_AMZ_ETSY.FinalData
        LIMIT 500000000
    """
    df = client.query(query).to_dataframe()
    df['Order Date'] = pd.to_datetime(df['Order Date'])
    df['year'] = df['Order Date'].dt.year
    return df

# T·∫£i d·ªØ li·ªáu
with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ BigQuery..."):
    df = load_data()

# T·∫°o c√°c tab
tab1, tab2, tab3 = st.tabs(["üìä T·ªïng Quan Doanh Thu", "üíµ D·ª± ƒêo√°n Doanh Thu", "üìÄ Ph√¢n C·ª•m Kh√°ch H√†ng"])

# Tab 1: T·ªïng Quan Doanh Thu
with tab1:
    st.header("üìä T·ªïng Quan Doanh Thu Theo NƒÉm")
    revenue_by_year = df.groupby('year')['Order Total'].sum().reset_index()

    # V·∫Ω bi·ªÉu ƒë·ªì doanh thu theo nƒÉm v·ªõi Plotly
    fig = px.bar(revenue_by_year, x='year', y='Order Total', title='T·ªïng Doanh Thu Theo NƒÉm',
                 labels={'year': 'NƒÉm', 'Order Total': 'T·ªïng Doanh Thu'}, color_discrete_sequence=['red'])
    fig.update_layout(xaxis_tickangle=0, yaxis=dict(griddash='dash', gridcolor='gray'))
    st.plotly_chart(fig)

   # Th√™m bi·ªÉu ƒë·ªì T·ªïng Order Total theo Sub-Category (ƒë·ªông)
    st.subheader("T·ªïng Order Total theo Sub-Category Theo NƒÉm")
    
    # T√≠nh t·ªïng Order Total theo Sub-Category v√† Year
    df['Year'] = df['Order Date'].dt.year
    pivot_data = df.groupby(['Year', 'Sub Category'])['Order Total'].sum().unstack()

    # L·∫•y danh s√°ch nƒÉm
    years = sorted(pivot_data.index)

    # ƒê·ªãnh nghƒ©a m√†u theo nƒÉm (3 nƒÉm g·∫ßn nh·∫•t)
    year_colors = {
        years[-3] if len(years) >= 3 else years[0]: '#1f77b4',  # blue
        years[-2] if len(years) >= 2 else years[0]: '#2ca02c',  # green
        years[-1] if len(years) >= 1 else years[0]: '#ff7f0e',  # orange
    }

    # Dropdown ƒë·ªÉ ch·ªçn nƒÉm
    selected_year = st.selectbox("Ch·ªçn nƒÉm:", years, index=len(years)-1)

    # V·∫Ω bi·ªÉu ƒë·ªì cho nƒÉm ƒë∆∞·ª£c ch·ªçn
    if years:
        data = pivot_data.loc[selected_year].sort_values()
        top5 = data.nlargest(5).index

        # ƒê·∫∑t m√†u: top 5 m√†u kh√°c (ƒë·∫≠m), c√≤n l·∫°i l√† m√†u nh·∫°t
        colors = [year_colors.get(selected_year, 'lightgray') if subcat in top5 else 'lightgray' for subcat in data.index]

        # T·∫°o figure
        plt.figure(figsize=(10, 6))
        bars = plt.barh(data.index, data.values, color=colors)
        
        # Ghi nh√£n gi√° tr·ªã tr√™n c·ªôt
        for bar in bars:
            width = bar.get_width()
            plt.text(width + 0.5, bar.get_y() + bar.get_height()/2,
                     f'{width:,.2f}', va='center', fontsize=9)

        plt.title(f'T·ªïng Doanh thu theo Sub-Category - NƒÉm {selected_year}')
        plt.xlabel('T·ªïng Order Total')
        plt.ylabel('Sub-Category')
        plt.grid(True, axis='x', linestyle='--', alpha=0.7)
        plt.tight_layout()
        
        # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì trong Streamlit
        st.pyplot(plt.gcf())
        plt.close()  # ƒê√≥ng figure ƒë·ªÉ tr√°nh xung ƒë·ªôt
    else:
        st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì theo Sub-Category.")
# Tab 2: D·ª± ƒêo√°n Doanh Thu
with tab2:
    st.header("üíµ D·ª± ƒêo√°n Doanh Thu v·ªõi Prophet")

    # Chu·∫©n b·ªã d·ªØ li·ªáu cho Prophet
    prophet_df = df[['Order Date', 'Order Total']].rename(columns={'Order Date': 'ds', 'Order Total': 'y'})
    prophet_df = prophet_df.groupby('ds').sum().reset_index()

    # L√†m m∆∞·ª£t d·ªØ li·ªáu th·ª±c t·∫ø
    prophet_df['y_smooth'] = prophet_df['y'].rolling(window=5, center=True, min_periods=1).mean()
    prophet_df['ds_numeric'] = prophet_df['ds'].apply(lambda x: x.timestamp())
    prophet_df = prophet_df.sort_values('ds_numeric')

    # N·ªôi suy ƒë·ªÉ l√†m m∆∞·ª£t
    x = prophet_df['ds_numeric']
    y = prophet_df['y_smooth']
    x_smooth = np.linspace(x.min(), x.max(), 500)
    spl = make_interp_spline(x, y, k=3)
    y_smooth = spl(x_smooth)
    ds_smooth = pd.to_datetime(x_smooth, unit='s')

    # Hu·∫•n luy·ªán m√¥ h√¨nh Prophet
    model = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=True, changepoint_prior_scale=0.01)
    model.fit(prophet_df)

    # Bi·ªÉu ƒë·ªì 1: Th·ª±c t·∫ø v√† d·ª± ƒëo√°n trong ph·∫°m vi d·ªØ li·ªáu g·ªëc
    past_future = prophet_df[['ds']].copy()
    past_forecast = model.predict(past_future)
    past_forecast['yhat_smooth'] = past_forecast['yhat'].rolling(window=5, center=True, min_periods=1).mean()
    past_forecast['yhat_lower_smooth'] = past_forecast['yhat_lower'].rolling(window=5, center=True, min_periods=1).mean()
    past_forecast['yhat_upper_smooth'] = past_forecast['yhat_upper'].rolling(window=5, center=True, min_periods=1).mean()

    # V·∫Ω bi·ªÉu ƒë·ªì v·ªõi Plotly
    fig1 = go.Figure()
    fig1.add_trace(go.Scatter(x=ds_smooth, y=y_smooth, mode='lines', name='Th·ª±c t·∫ø', line=dict(color='blue', width=1)))
    fig1.add_trace(go.Scatter(x=past_forecast['ds'], y=past_forecast['yhat_smooth'], mode='lines', name='D·ª± ƒëo√°n', line=dict(color='orange', width=1)))
    fig1.add_trace(go.Scatter(x=past_forecast['ds'], y=past_forecast['yhat_upper_smooth'], mode='lines', name='Kho·∫£ng tin c·∫≠y (tr√™n)', line=dict(color='yellow', width=0), showlegend=False))
    fig1.add_trace(go.Scatter(x=past_forecast['ds'], y=past_forecast['yhat_lower_smooth'], mode='lines', name='Kho·∫£ng tin c·∫≠y (d∆∞·ªõi)', line=dict(color='yellow', width=0), fill='tonexty', fillcolor='rgba(255, 255, 0, 0.2)'))
    fig1.update_layout(title='Gi√° tr·ªã b√°n h√†ng h√†ng th√°ng - Prophet (T·∫≠p g·ªëc)', xaxis_title='Ng√†y', yaxis_title='Gi√° tr·ªã b√°n h√†ng', xaxis_tickformat='%Y-%m', xaxis_tickangle=45, yaxis=dict(griddash='dash', gridcolor='gray'))
    st.plotly_chart(fig1)

    # Bi·ªÉu ƒë·ªì 2: D·ª± ƒëo√°n 12 th√°ng ti·∫øp theo
    future = model.make_future_dataframe(periods=365, freq='D')
    future_forecast = model.predict(future)
    future_forecast['yhat_smooth'] = future_forecast['yhat'].rolling(window=5, center=True, min_periods=1).mean()
    future_forecast['yhat_lower_smooth'] = future_forecast['yhat_lower'].rolling(window=5, center=True, min_periods=1).mean()
    future_forecast['yhat_upper_smooth'] = future_forecast['yhat_upper'].rolling(window=5, center=True, min_periods=1).mean()

    # V·∫Ω bi·ªÉu ƒë·ªì d·ª± ƒëo√°n t∆∞∆°ng lai
    fig2 = go.Figure()
    fig2.add_trace(go.Scatter(x=ds_smooth, y=y_smooth, mode='lines', name='Th·ª±c t·∫ø', line=dict(color='blue', width=1)))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              y=future_forecast['yhat_smooth'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              mode='lines', name='D·ª± ƒëo√°n', line=dict(color='orange', width=1)))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] > prophet_df['ds'].max()],
                              y=future_forecast['yhat_smooth'][future_forecast['ds'] > prophet_df['ds'].max()],
                              mode='lines', name='D·ª± ƒëo√°n t∆∞∆°ng lai', line=dict(color='red', width=1)))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              y=future_forecast['yhat_upper_smooth'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              mode='lines', name='Kho·∫£ng tin c·∫≠y', line=dict(color='yellow', width=0), showlegend=False))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              y=future_forecast['yhat_lower_smooth'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              mode='lines', name='Kho·∫£ng tin c·∫≠y', line=dict(color='yellow', width=0), fill='tonexty', fillcolor='rgba(255, 255, 0, 0.2)'))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] > prophet_df['ds'].max()],
                              y=future_forecast['yhat_upper_smooth'][future_forecast['ds'] > prophet_df['ds'].max()],
                              mode='lines', name='Kho·∫£ng tin c·∫≠y t∆∞∆°ng lai', line=dict(color='pink', width=0), showlegend=False))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] > prophet_df['ds'].max()],
                              y=future_forecast['yhat_lower_smooth'][future_forecast['ds'] > prophet_df['ds'].max()],
                              mode='lines', name='Kho·∫£ng tin c·∫≠y t∆∞∆°ng lai', line=dict(color='pink', width=0), fill='tonexty', fillcolor='rgba(255, 192, 203, 0.2)'))
    fig2.update_layout(title='D·ª± ƒëo√°n gi√° tr·ªã b√°n h√†ng 12 th√°ng ti·∫øp theo - Prophet', xaxis_title='Ng√†y', yaxis_title='Gi√° tr·ªã b√°n h√†ng', xaxis_tickformat='%Y-%m', xaxis_tickangle=45, yaxis=dict(griddash='dash', gridcolor='gray'))
    st.plotly_chart(fig2)

    # Hi·ªÉn th·ªã c√°c ch·ªâ s·ªë ƒë√°nh gi√°
    eval_df = pd.merge(prophet_df[['ds', 'y']], past_forecast[['ds', 'yhat']], on='ds')
    mae = mean_absolute_error(eval_df['y'], eval_df['yhat'])
    rmse = np.sqrt(mean_squared_error(eval_df['y'], eval_df['yhat']))
    mape = np.mean(np.abs((eval_df['y'] - eval_df['yhat']) / eval_df['y'])) * 100
    r2 = r2_score(eval_df['y'], eval_df['yhat'])

    st.subheader("ƒê√°nh Gi√° M√¥ H√¨nh D·ª± ƒêo√°n")
    st.write(f"üìä MAE: {mae:.2f}")
    st.write(f"üìä RMSE: {rmse:.2f}")
    st.write(f"üìä MAPE: {mape:.2f}%")
    st.write(f"üìä R¬≤ Score: {r2:.2f}")

    # Th√™m m·ª•c ch·ªçn ng√†y ƒë·ªÉ d·ª± ƒëo√°n doanh thu
    st.subheader("D·ª± ƒêo√°n Doanh Thu Cho Ng√†y C·ª• Th·ªÉ")
    today = datetime.today().date()
    max_date = today + timedelta(days=365)  # Gi·ªõi h·∫°n 1 nƒÉm t·ª´ h√¥m nay
    selected_date = st.date_input("Ch·ªçn ng√†y trong t∆∞∆°ng lai ƒë·ªÉ d·ª± ƒëo√°n doanh thu:", 
                                  min_value=today, 
                                  max_value=max_date, 
                                  value=today + timedelta(days=30))

    # D·ª± ƒëo√°n cho ng√†y ƒë∆∞·ª£c ch·ªçn
    selected_date_df = pd.DataFrame({'ds': [pd.to_datetime(selected_date)]})
    selected_forecast = model.predict(selected_date_df)

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± ƒëo√°n
    st.markdown(f"**D·ª± ƒëo√°n doanh thu cho ng√†y {selected_date}:**")
    st.write(f"üìà Gi√° tr·ªã d·ª± ƒëo√°n: **${selected_forecast['yhat'].iloc[0]:,.2f}**")
    st.write(f"üìâ Kho·∫£ng tin c·∫≠y th·∫•p: **${selected_forecast['yhat_lower'].iloc[0]:,.2f}**")
    st.write(f"üìä Kho·∫£ng tin c·∫≠y cao: **${selected_forecast['yhat_upper'].iloc[0]:,.2f}**")
# Tab 3: Ph√¢n C·ª•m Kh√°ch H√†ng
with tab3:
    st.header("üìÄ Ph√¢n C·ª•m Kh√°ch H√†ng v·ªõi GMM")

    # L·∫•y m·∫´u d·ªØ li·ªáu
    df_sample = df.sample(n=35000, random_state=42)
    df_cluster = df_sample[['Product Cost', 'Shipping Fee', 'Order Total', 'Profit']]

    # Chu·∫©n h√≥a v√† PCA
    scaler = StandardScaler()
    df_scaled = scaler.fit_transform(df_cluster)
    pca = PCA(n_components=2)
    df_pca = pca.fit_transform(df_scaled)

    # Ph√¢n c·ª•m v·ªõi GMM
    gmm = GaussianMixture(n_components=7, random_state=42)
    clusters = gmm.fit_predict(df_pca)
    df_sample['Cluster'] = clusters

    # V·∫Ω bi·ªÉu ƒë·ªì ph√¢n c·ª•m
    fig3 = px.scatter(x=df_pca[:, 0], y=df_pca[:, 1], color=clusters.astype(str), title='Ph√¢n C·ª•m Kh√°ch H√†ng v·ªõi GMM',
                      labels={'x': 'PCA 1', 'y': 'PCA 2', 'color': 'Cluster'}, color_discrete_sequence=px.colors.qualitative.T10)
    fig3.update_layout(showlegend=True)
    st.plotly_chart(fig3)

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ ph√¢n c·ª•m
    st.subheader("K·∫øt Qu·∫£ Ph√¢n C·ª•m (M·∫´u)")
    st.dataframe(df_sample[['Order Id', 'City', 'Country', 'Cluster']].head())

    # Ph√¢n t√≠ch ƒë·∫∑c tr∆∞ng t·ª´ng c·ª•m
    df_analysis = df_sample[['Product Cost', 'Shipping Fee', 'Order Total', 'Profit', 'Cluster']].copy()
    cluster_summary = df_analysis.groupby('Cluster').mean().round(2)
    cluster_counts = df_analysis['Cluster'].value_counts().sort_index()
    cluster_summary['Count'] = cluster_counts

    st.subheader("ƒê·∫∑c Tr∆∞ng Trung B√¨nh c·ªßa T·ª´ng C·ª•m")
    st.dataframe(cluster_summary)

    # ƒê√°nh gi√° m√¥ h√¨nh ph√¢n c·ª•m (t·ª´ Tab 4)
    st.subheader("ƒê√°nh Gi√° M√¥ H√¨nh Ph√¢n C·ª•m")
    df_valid = df_sample.dropna(subset=['Cluster'])
    X_valid = df_pca
    labels = df_valid['Cluster']

    sil_score = silhouette_score(X_valid, labels)
    db_index = davies_bouldin_score(X_valid, labels)
    ch_index = calinski_harabasz_score(X_valid, labels)

    st.write(f"üìä Silhouette Score: {sil_score:.3f}")
    st.write(f"üìä Davies-Bouldin Index: {db_index:.3f}")
    st.write(f"üìä Calinski-Harabasz Index: {ch_index:.3f}")
    st.write(f"üìä S·ªë c·ª•m: {len(set(labels))}")

# Footer
st.markdown("---")
st.markdown("Web App Demo ƒê·ªÅ √Ån T·ªët Nghi·ªáp ƒë∆∞·ª£c x√¢y d·ª±ng v·ªõi Streamlit b·ªüi ·∫§n Ng·ªçc . Li√™n h·ªá h·ªó tr·ª£: anngocmukbang@gmail.com")
